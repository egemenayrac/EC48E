{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 0) SET-UP\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, f1_score \n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 1) HİPERPARAMETRE ARAMASI  (Time-series CV) - CLASS WEIGHTS İLE\n",
    "# ==============================================================\n",
    "try:\n",
    "    tscv = TimeSeriesSplitBoth(n_splits=5, test_size=12, min_pos=1, min_neg=1)\n",
    "    print(\"Using TimeSeriesSplitBoth for cross-validation.\")\n",
    "except NameError:\n",
    "    print(\"TimeSeriesSplitBoth not defined. Falling back to TimeSeriesSplit. Ensure TimeSeriesSplitBoth is defined and executed in a previous cell.\")\n",
    "    tscv = TimeSeriesSplit(n_splits=5, test_size=12)\n",
    "\n",
    "\n",
    "# RandomForestClassifier - SMOTE kaldırıldı\n",
    "rf_model = RandomForestClassifier(random_state=42, bootstrap=True, oob_score=True) # oob_score=True eklendi\n",
    "\n",
    "# Parametre gridi güncellendi - SMOTE parametreleri kaldırıldı, rf__ önekleri kaldırıldı\n",
    "param_grid = {\n",
    "    'n_estimators'     : [50, 100, 150], \n",
    "    'max_depth'        : [2, 3, 4, 5], # Slightly increased max_depth options\n",
    "    'min_samples_leaf' : [10, 15, 20],   \n",
    "    'min_samples_split': [20, 30, 40],  \n",
    "    'max_features'     : ['sqrt', 0.4, 0.6], \n",
    "    'class_weight'     : ['balanced', 'balanced_subsample', None] \n",
    "}\n",
    "\n",
    "gcv = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid,\n",
    "    scoring='f1', # 1-sınıfı için F1 skoruna odaklanıyoruz\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gcv.fit(X, y)\n",
    "\n",
    "print(\"\\nBest parameters (with class weights):\", gcv.best_params_)\n",
    "print(\"Best F1 on time series (with class weights):\", gcv.best_score_.round(3))\n",
    "\n",
    "# ==============================================================\n",
    "# 1.1) ÖZELLİK ÖNEMLERİNİ GÖSTER (EN İYİ MODEL İLE)\n",
    "# ==============================================================\n",
    "best_rf_model = gcv.best_estimator_ \n",
    "feature_importances = pd.Series(best_rf_model.feature_importances_, index=X.columns)\n",
    "print(\"\\nFeature Importances (from best RF model):\")\n",
    "print(feature_importances.sort_values(ascending=False))\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2) EN İYİ MODELİ FULL TRAIN,  OOB & CV KARŞILAŞTIR\n",
    "# ==============================================================\n",
    "\n",
    "best_rf = gcv.best_estimator_ \n",
    "\n",
    "if hasattr(best_rf, 'oob_decision_function_') and best_rf.oob_decision_function_ is not None:\n",
    "    oob_pred_proba_rf = best_rf.oob_decision_function_\n",
    "    if oob_pred_proba_rf.ndim == 2:\n",
    "        oob_pred_rf = (oob_pred_proba_rf[:, 1] > 0.5).astype(int) \n",
    "        report_oob_rf = classification_report(y, oob_pred_rf, output_dict=True, zero_division=0, labels=np.unique(y))\n",
    "        if '1' in report_oob_rf and isinstance(report_oob_rf['1'], dict) and 'f1-score' in report_oob_rf['1']:\n",
    "            oob_f1_rf = report_oob_rf['1']['f1-score']\n",
    "            print(\"OOB F1 (Random Forest, threshold 0.5):\", round(oob_f1_rf, 3))\n",
    "        elif 1 in report_oob_rf and isinstance(report_oob_rf[1], dict) and 'f1-score' in report_oob_rf[1]: # Check for int key\n",
    "            oob_f1_rf = report_oob_rf[1]['f1-score']\n",
    "            print(\"OOB F1 (Random Forest, threshold 0.5):\", round(oob_f1_rf, 3))\n",
    "        else:\n",
    "            print(\"OOB F1 (Random Forest): Class '1' veya F1 skoru OOB raporunda bulunamadı.\")\n",
    "            oob_f1_rf = 0.0\n",
    "    else:\n",
    "        print(\"OOB decision function (Random Forest) uygun formatta değil.\")\n",
    "        oob_f1_rf = 0.0\n",
    "elif hasattr(best_rf, 'oob_score_'):\n",
    "     print(f\"OOB Accuracy (Random Forest): {best_rf.oob_score_:.3f} (F1 score for OOB requires oob_decision_function)\")\n",
    "     oob_f1_rf = 0.0 \n",
    "else:\n",
    "    print(\"Random Forest modeli 'oob_decision_function_' veya 'oob_score_' özelliğine sahip değil.\")\n",
    "    oob_f1_rf = 0.0\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 3) FORWARD WALK  —  SON FOLD’U GERÇEK TEST GİBİ RAPORLA\n",
    "# ==============================================================\n",
    "\n",
    "all_splits = list(tscv.split(X, y))\n",
    "split_to_test_idx = 1 \n",
    "\n",
    "if len(all_splits) > split_to_test_idx:\n",
    "    print(f\"Test için {split_to_test_idx}. indeksli zaman serisi katmanı kullanılıyor.\")\n",
    "    train_idx, test_idx = all_splits[split_to_test_idx]\n",
    "else:\n",
    "    print(f\"Uyarı: İstenen katman ({split_to_test_idx}) bulunamadı. Son mevcut katman kullanılacak.\")\n",
    "    if len(all_splits) > 0:\n",
    "        train_idx, test_idx = all_splits[-1]\n",
    "    else:\n",
    "        raise ValueError(\"No splits available from TimeSeriesSplit. Check CV parameters and data size.\")\n",
    "\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_test , y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "print(f\"Kullanılan Eğitim Seti Boyutu: {X_train.shape[0]}, Test Seti Boyutu: {X_test.shape[0]}\")\n",
    "print(\"Kullanılan Test Setindeki (y_test) Sınıf Dağılımı:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "if 1 not in y_test.value_counts():\n",
    "    print(\"UYARI: Seçilen bu test katmanında '1' sınıfı bulunmuyor. 'split_to_test_idx'yi veya TimeSeriesSplit ayarlarını gözden geçirin.\")\n",
    "\n",
    "best_rf.fit(X_train, y_train) \n",
    "\n",
    "# --- PROBABILITY THRESHOLD TUNING ---\n",
    "# Revised to maximize F1-score for class 1 on the test set\n",
    "y_pred_proba_test_rf = best_rf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "optimal_threshold_rf = 0.5 \n",
    "best_f1_class1_rf_tuned = -1.0\n",
    "\n",
    "potential_thresholds = np.arange(0.05, 1.0, 0.01)\n",
    "print(\"\\nTuning probability threshold for Random Forest to maximize F1-score for class 1...\")\n",
    "for current_thresh in potential_thresholds:\n",
    "    y_pred_temp_rf = (y_pred_proba_test_rf >= current_thresh).astype(int)\n",
    "    current_f1_class1 = f1_score(y_test, y_pred_temp_rf, pos_label=1, zero_division=0)\n",
    "    \n",
    "    if current_f1_class1 > best_f1_class1_rf_tuned:\n",
    "        best_f1_class1_rf_tuned = current_f1_class1\n",
    "        optimal_threshold_rf = current_thresh\n",
    "\n",
    "print(f\"Optimal threshold for RF found: {optimal_threshold_rf:.2f} (Maximizing F1 Class 1: {best_f1_class1_rf_tuned:.3f})\")\n",
    "y_pred_rf_tuned = (y_pred_proba_test_rf >= optimal_threshold_rf).astype(int)\n",
    "# --- END THRESHOLD TUNING ---\n",
    "\n",
    "unique_labels_in_y = np.unique(y_test) # Use y_test for labels in confusion matrix and report\n",
    "if len(unique_labels_in_y) < 2 and len(np.unique(y)) == 2: # If test set has only one class, use all possible labels from y\n",
    "    unique_labels_in_y = np.unique(y)\n",
    "\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf_tuned, labels=unique_labels_in_y)\n",
    "print(f\"\\nConfusion Matrix (Random Forest, test katmanı {split_to_test_idx}, tuned threshold):\")\n",
    "print(cm_rf)\n",
    "\n",
    "print(f\"\\nClassification Report (Random Forest, test katmanı {split_to_test_idx}, tuned threshold):\")\n",
    "print(classification_report(y_test, y_pred_rf_tuned, digits=3, labels=unique_labels_in_y, zero_division=0))\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 4) BASİT OVERFITTING GÖSTERGESİ\n",
    "# ==============================================================\n",
    "y_pred_proba_train_rf = best_rf.predict_proba(X_train)[:, 1]\n",
    "y_pred_train_rf_tuned = (y_pred_proba_train_rf >= optimal_threshold_rf).astype(int)\n",
    "\n",
    "report_train_rf = classification_report(y_train, y_pred_train_rf_tuned, output_dict=True, zero_division=0, labels=unique_labels_in_y)\n",
    "train_f1_rf = 0.0\n",
    "# Ensure class '1' (represented as int 1 or str '1') is checked correctly\n",
    "if '1' in report_train_rf and isinstance(report_train_rf['1'], dict):\n",
    "    train_f1_rf = report_train_rf['1'].get('f1-score', 0.0)\n",
    "elif 1 in report_train_rf and isinstance(report_train_rf[1], dict): \n",
    "    train_f1_rf = report_train_rf[1].get('f1-score', 0.0)\n",
    "\n",
    "\n",
    "report_test_rf = classification_report(y_test , y_pred_rf_tuned, output_dict=True, zero_division=0, labels=unique_labels_in_y)\n",
    "test_f1_rf = 0.0\n",
    "if '1' in report_test_rf and isinstance(report_test_rf['1'], dict):\n",
    "    test_f1_rf = report_test_rf['1'].get('f1-score', 0.0)\n",
    "elif 1 in report_test_rf and isinstance(report_test_rf[1], dict):\n",
    "    test_f1_rf = report_test_rf[1].get('f1-score', 0.0)\n",
    "\n",
    "\n",
    "print(f\"\\nF1 (Random Forest, train) = {train_f1_rf:.3f} | F1 (Random Forest, test) = {test_f1_rf:.3f} (using tuned threshold {optimal_threshold_rf:.2f})\")\n",
    "\n",
    "if train_f1_rf - test_f1_rf > 0.10:\n",
    "    print(\"⚠️ RF >0.10 fark → overfitting; max_depth, min_samples_leaf.\")\n",
    "\n",
    "# ==============================================================\n",
    "# 5) (Opsiyonel) BalancedRandomForest ile hızlı karşılaştırma\n",
    "# ==============================================================\n",
    "\n",
    "# Adjusting BRF parameters to reduce overfitting\n",
    "brf_n_estimators = gcv.best_params_.get('n_estimators', 100)\n",
    "brf_max_depth = gcv.best_params_.get('max_depth', 3) # Using max_depth from best RF model\n",
    "\n",
    "brf = BalancedRandomForestClassifier(\n",
    "    n_estimators=brf_n_estimators, \n",
    "    max_depth=brf_max_depth, \n",
    "    random_state=42,\n",
    "    # class_weight='balanced' is implicit in BalancedRandomForestClassifier by resampling\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "y_pred_brf_test = brf.predict(X_test) \n",
    "\n",
    "print(f\"\\nBalancedRF — test confusion (n_estimators={brf_n_estimators}, max_depth={brf_max_depth}):\")\n",
    "print(confusion_matrix(y_test, y_pred_brf_test, labels=unique_labels_in_y))\n",
    "print(f\"\\nBalancedRF — classification report (n_estimators={brf_n_estimators}, max_depth={brf_max_depth}):\")\n",
    "print(classification_report(y_test, y_pred_brf_test, digits=3, labels=unique_labels_in_y, zero_division=0))\n",
    "\n",
    "# Overfitting check for BRF\n",
    "y_pred_brf_train = brf.predict(X_train)\n",
    "report_train_brf = classification_report(y_train, y_pred_brf_train, output_dict=True, zero_division=0, labels=unique_labels_in_y)\n",
    "train_f1_brf = 0.0\n",
    "if '1' in report_train_brf and isinstance(report_train_brf['1'], dict):\n",
    "    train_f1_brf = report_train_brf['1'].get('f1-score', 0.0)\n",
    "elif 1 in report_train_brf and isinstance(report_train_brf[1], dict):\n",
    "    train_f1_brf = report_train_brf[1].get('f1-score', 0.0)\n",
    "\n",
    "report_test_brf = classification_report(y_test, y_pred_brf_test, output_dict=True, zero_division=0, labels=unique_labels_in_y)\n",
    "test_f1_brf = 0.0\n",
    "if '1' in report_test_brf and isinstance(report_test_brf['1'], dict):\n",
    "    test_f1_brf = report_test_brf['1'].get('f1-score', 0.0)\n",
    "elif 1 in report_test_brf and isinstance(report_test_brf[1], dict):\n",
    "    test_f1_brf = report_test_brf[1].get('f1-score', 0.0)\n",
    "\n",
    "print(f\"F1 (BalancedRF, train) = {train_f1_brf:.3f} | F1 (BalancedRF, test) = {test_f1_brf:.3f}\")\n",
    "if abs(train_f1_brf - test_f1_brf) > 0.10 and train_f1_brf > test_f1_brf : # Check for significant drop\n",
    "    print(\"⚠️ BRF >0.10 fark → overfitting.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f375f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 1) Imports\n",
    "# ============================================================== \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, confusion_matrix,\n",
    "    classification_report, make_scorer\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================================\n",
    "# 2) Cross-validator: 5 folds, 18-month test blocks,\n",
    "#    each test block must contain ≥1 positive & ≥1 negative\n",
    "# ============================================================== \n",
    "cv = TimeSeriesSplitBoth(\n",
    "        n_splits = 5,\n",
    "        test_size = 18,\n",
    "        min_pos = 1,\n",
    "        min_neg = 1\n",
    ")\n",
    "\n",
    "# ==============================================================\n",
    "# 3) Model + grid\n",
    "# ============================================================== \n",
    "ratio = (y == 0).sum() / (y == 1).sum()       # class imbalance\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "        objective = \"binary:logistic\",\n",
    "        eval_metric = \"logloss\",\n",
    "        random_state = 42,\n",
    "        tree_method = \"hist\",     # fastest on CPU\n",
    "        n_jobs = -1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\"      : [100, 150, 200],\n",
    "    \"learning_rate\"     : [0.05, 0.1],\n",
    "    \"max_depth\"         : [2, 3],\n",
    "    \"subsample\"         : [0.8, 1.0],\n",
    "    \"colsample_bytree\"  : [0.6, 0.8],\n",
    "    \"gamma\"             : [0, 0.5],\n",
    "    \"scale_pos_weight\"  : [ratio, ratio * 1.5]   # class weight\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "gcv = GridSearchCV(\n",
    "        estimator  = xgb,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = scorer,\n",
    "        cv         = cv,\n",
    "        n_jobs     = -1,\n",
    "        verbose    = 2,\n",
    "        refit      = True\n",
    ")\n",
    "\n",
    "print(\" Grid-searching XGBoost …\")\n",
    "gcv.fit(X, y)\n",
    "\n",
    "print(\"\\nBest CV F1 (class 1):\", round(gcv.best_score_, 3))\n",
    "print(\"Best hyper-parameters:\")\n",
    "for k, v in gcv.best_params_.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# ==============================================================\n",
    "# 4) Final hold-out = last fold   (never seen during CV)\n",
    "# ============================================================== \n",
    "splits       = list(cv.split(X, y))\n",
    "train_idx, test_idx = splits[-1]\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_test , y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "best_xgb = gcv.best_estimator_.fit(X_train, y_train)\n",
    "\n",
    "# ===== probability → threshold search (macro-F1) ==============\n",
    "proba = best_xgb.predict_proba(X_test)[:, 1]\n",
    "ths   = np.linspace(0.2, 0.8, 13)\n",
    "\n",
    "best_f1, best_t = 0, 0.5\n",
    "for t in ths:\n",
    "    f1 = f1_score(y_test, proba > t, pos_label=1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "\n",
    "print(f\"\\nOptimal threshold: {best_t:.2f}  (F1₁ = {best_f1:.3f})\")\n",
    "y_pred = (proba > best_t).astype(int)\n",
    "\n",
    "# ==============================================================\n",
    "# 5) Reports  –  overfitting check\n",
    "# ============================================================== \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix (hold-out):\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification report (hold-out):\")\n",
    "print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
    "\n",
    "# Train-set report\n",
    "train_report = classification_report(\n",
    "        y_train,\n",
    "        best_xgb.predict(X_train) > 0.5,     # default 0.5 for train\n",
    "        digits=3, output_dict=True,\n",
    "        zero_division=0\n",
    ")\n",
    "\n",
    "train_f1 = train_report['1']['f1-score']\n",
    "test_f1  = best_f1\n",
    "print(f\"\\nF1 (train) = {train_f1:.3f} | F1 (test) = {test_f1:.3f}\")\n",
    "\n",
    "if train_f1 - test_f1 > 0.10:\n",
    "    print(\"⚠️  >0.10 gap → potential overfitting; reduce max_depth or n_estimators.\")\n",
    "else:\n",
    "    print(\"✅  No significant overfitting gap detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6feaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 0) SET–UP\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# -------------------- feature / target ------------------------\n",
    "monthly['high_vol_next'] = monthly['high_vol'].shift(-1)\n",
    "monthly = monthly.dropna(subset=['high_vol_next'])\n",
    "\n",
    "y = monthly['high_vol_next'].astype(int)\n",
    "X = monthly.drop(columns=['high_vol', 'high_vol_next'])\n",
    "\n",
    "# sınıf dengesizliği oranı (0=low, 1=high)\n",
    "scale_pos = (y == 0).sum() / (y == 1).sum()\n",
    "\n",
    "# ==============================================================\n",
    "# 1) HİPERPARAMETRE ARAMASI  (Time-series CV)\n",
    "# ==============================================================\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=6)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators'     : [300, 500, 800],\n",
    "    'max_depth'        : [2, 3, 4],\n",
    "    'learning_rate'    : [0.05, 0.1],\n",
    "    'subsample'        : [0.7, 0.9],\n",
    "    'colsample_bytree' : [0.6, 0.8],\n",
    "    'gamma'            : [0, 1],          # minimum loss reduction\n",
    "    'min_child_weight' : [1, 5],\n",
    "    'scale_pos_weight' : [scale_pos]      # class imbalance\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gcv = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gcv.fit(X, y)\n",
    "\n",
    "print(\"En iyi parametreler:\", gcv.best_params_)\n",
    "print(\"Time-series CV’de en iyi F1:\", round(gcv.best_score_, 3))\n",
    "\n",
    "# ==============================================================\n",
    "# 2) EN İYİ MODELİ FULL TRAIN,  TRAIN-TEST KARŞILAŞTIR\n",
    "# ==============================================================\n",
    "\n",
    "best_xgb = gcv.best_estimator_\n",
    "\n",
    "# Bilinen etiketler (sınıflar)\n",
    "known_labels = sorted(y.unique()) # Genellikle [0, 1] olacaktır\n",
    "\n",
    "# Test için katman seçimi: Son 6 ayda '1' sınıfı bulunmadığından,\n",
    "# '1' sınıfını içeren ve daha anlamlı bir değerlendirme sunacak\n",
    "# farklı bir katman seçiyoruz (örneğin, sondan 4. katman - index 1).\n",
    "# Bu katman 2023-06-30 tarihindeki 'high_vol = 1' verisini içerir.\n",
    "all_splits = list(tscv.split(X, y))\n",
    "# train_idx, test_idx = all_splits[-1] # Önceki: Sadece son 6 ayı alıyordu, '1' içermiyordu.\n",
    "\n",
    "chosen_fold_idx = 1 # Sondan 4. katman (0-indeksli)\n",
    "if len(all_splits) > chosen_fold_idx and chosen_fold_idx < len(all_splits):\n",
    "    print(f\"\\nDeğerlendirme için {chosen_fold_idx}. indeksli zaman serisi katmanı kullanılıyor.\")\n",
    "    train_idx, test_idx = all_splits[chosen_fold_idx]\n",
    "else:\n",
    "    print(f\"Uyarı: İstenen katman ({chosen_fold_idx}) bulunamadı. Son mevcut katman kullanılacak.\")\n",
    "    train_idx, test_idx = all_splits[-1]\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "X_test , y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n",
    "\n",
    "print(f\"Kullanılan Eğitim Seti Boyutu: {X_train.shape[0]}, Test Seti Boyutu: {X_test.shape[0]}\")\n",
    "print(\"Kullanılan Test Setindeki (y_test) Sınıf Dağılımı:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "if 1 not in y_test.value_counts():\n",
    "    print(\"UYARI: Seçilen bu test katmanında '1' sınıfı bulunmuyor. Farklı bir 'chosen_fold_idx' deneyin veya TimeSeriesSplit ayarlarını gözden geçirin.\")\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = best_xgb.predict(X_train)\n",
    "y_pred_test  = best_xgb.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=known_labels)\n",
    "print(f\"\\nConfusion Matrix (seçilen test katmanı {chosen_fold_idx}):\\n\", cm)\n",
    "\n",
    "print(f\"\\nClassification Report (test katmanı {chosen_fold_idx}):\\n\",\n",
    "      classification_report(y_test, y_pred_test, digits=3, labels=known_labels, zero_division=0))\n",
    "\n",
    "report_train_dict = classification_report(y_train, y_pred_train, output_dict=True, labels=known_labels, zero_division=0)\n",
    "report_test_dict  = classification_report(y_test,  y_pred_test, output_dict=True, labels=known_labels, zero_division=0)\n",
    "\n",
    "# '1' sınıfı için F1 skorunu güvenli bir şekilde al\n",
    "train_f1 = report_train_dict.get(str(known_labels[1]), {}).get('f1-score', 0.0) if len(known_labels) > 1 else report_train_dict.get('1', {}).get('f1-score', 0.0)\n",
    "test_f1  = report_test_dict.get(str(known_labels[1]), {}).get('f1-score', 0.0) if len(known_labels) > 1 else report_test_dict.get('1', {}).get('f1-score', 0.0)\n",
    "\n",
    "print(f\"\\nF1 (train) = {train_f1:.3f} | F1 (test) = {test_f1:.3f}\")\n",
    "\n",
    "if train_f1 > 0 and abs(train_f1 - test_f1) > 0.10 : # train_f1 > 0 kontrolü eklendi\n",
    "    print(\"⚠️  >0.10 fark → olası overfitting; \"\n",
    "          \"learning_rate’i düşürüp n_estimators’ı artırmayı, \"\n",
    "          \"veya max_depth’i küçültmeyi deneyin.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2683fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
